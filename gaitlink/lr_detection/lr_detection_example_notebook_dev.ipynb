{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaitlink.data import load_mobilised_matlab_format, get_all_lab_example_data_paths\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ARNE: String enum should be available in the standard library\n",
    "from enum import StrEnum\n",
    "# from strenum import StrEnum\n",
    "from typing import Union\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "from tpcp import Algorithm\n",
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from gaitlink.data import LabExampleDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "#           Load some example data\n",
    "# ---------------------------------------------\n",
    "\n",
    "dataset = LabExampleDataset(reference_system=\"INDIP\")\n",
    "datapoint = dataset.get_subset(cohort=\"HA\", participant_id=\"001\", test=\"Test11\", trial=\"Trial1\")\n",
    "imu_data = datapoint.data[\"LowerBack\"]\n",
    "\n",
    "ref_data = datapoint.reference_parameters_\n",
    "ref_walking_bouts = ref_data.walking_bouts\n",
    "sampling_rate_hz = datapoint.sampling_rate_hz\n",
    "sampling_rate_hz_ref = datapoint.reference_sampling_rate_hz_\n",
    "\n",
    "ref_ics = ref_data.initial_contacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment the data according to Gait Sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok, we can now write a function to iterate through all the walking bouts (or gait sequences (GS)) and extract the reference IC locations and LR labels, relative to the start of each walking bout.\n",
    "# also, keep in mind that event_list is no longer necessary here..\n",
    "\n",
    "data_list = []\n",
    "ic_list = []\n",
    "label_list = []\n",
    "\n",
    "for gs in range(len(ref_walking_bouts)):\n",
    "    gs_start = ref_walking_bouts.iloc[gs].start\n",
    "    gs_end = ref_walking_bouts.iloc[gs].end\n",
    "    \n",
    "    data_list.append(imu_data.iloc[gs_start : gs_end].reset_index(drop = True))\n",
    "    ic_list.append(ref_ics.loc[ref_ics.index.get_level_values('wb_id') == gs + 1, ['ic']].reset_index(drop = True) - gs_start) \n",
    "    label_list.append(ref_ics.loc[ref_ics.index.get_level_values('wb_id') == gs + 1, ['lr_label']].reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McCamley Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_lr_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predicted_lr_label\n",
       "0               Left\n",
       "1               Left\n",
       "2               Left\n",
       "3              Right\n",
       "4               Left\n",
       "5              Right\n",
       "6               Left"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gaitlink.lr_detection._lr_detect_McCamley import McCamleyLRDetection\n",
    "\n",
    "my_algo = McCamleyLRDetection()\n",
    "my_algo.detect(data_list[0], ic_list[0])\n",
    "\n",
    "my_algo.ic_lr\n",
    "\n",
    "# then, you can simply loop through all the gait sequences. This \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lr_label\n",
       "0     Left\n",
       "1    Right\n",
       "2     Left\n",
       "3    Right\n",
       "4     Left\n",
       "5    Right\n",
       "6     Left"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list[0]\n",
    "\n",
    "# this works, but is misclassifying the second IC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "class PretrainedModel(StrEnum):\n",
    "    \"\"\"\n",
    "    Enum class for the pretrained models.\n",
    "    \"\"\"\n",
    "    # ARNE: I think the pretrained Models that Martin had all used the same ML Algo, but where trained on different datasets\n",
    "    # ALEX: Correct, but the reference paper states all of them, so I just assumed that the other options might be available as well.\n",
    "    svm_linear = \"svm_linear\"\n",
    "    svm_rbf = \"svm_rbf\"\n",
    "    knn = \"knn\"\n",
    "    rfc = \"rfc\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_pretrained_model(model_name):\n",
    "        \n",
    "        if model_name == PretrainedModel.svm_linear:\n",
    "            # model_path = \"C:\\\\Users\\\\mer20as\\\\Documents\\\\PhD_Repos\\\\gaitlink\\\\gaitlink\\\\lr_detection\\\\pretrained_models\\\\msproject_ms_model.gz\"\n",
    "            base_dir = Path(os.getenv('MODEL_DIR', './pretrained_models'))\n",
    "            model_path = base_dir / 'msproject_ms_model.gz'\n",
    "            return joblib.load(model_path)\n",
    "    \n",
    "        # ARNE: These are not really pretrained models right? They are just optimized Hyper Paras\n",
    "        # ALEX: Yes, I have put them here for convenience, since I did not have the other pre-trained models.\n",
    "        elif model_name == \"svm_rbf\":\n",
    "            return svm.SVC(kernel='rbf',\n",
    "                           C=100, gamma=0.001,\n",
    "                           probability=True)\n",
    "            \n",
    "        elif model_name == PretrainedModel.knn:\n",
    "            return neighbors.KNeighborsClassifier(n_neighbors = 5)\n",
    "        \n",
    "        elif model_name == PretrainedModel.rfc:\n",
    "            return RandomForestClassifier(n_estimators = 100,\n",
    "                                          max_depth = 2,\n",
    "                                          random_state = 0)\n",
    "        else:\n",
    "            raise NotImplementedError(\"The model specified is not supported yet.\")\n",
    "        \n",
    "        \n",
    "class BaseLRDetection(Algorithm):\n",
    "    lr_list_: list\n",
    "    \n",
    "    def detect(self, data: pd.DataFrame):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of things to remember:\n",
    "* Optimization of the `parameters` specified in the `__init__` of the the algorithm is performed via _internal_ optimization implemented in a `self_optimize` method.\n",
    "* There should also be an option to perform _external_ optimization using the `GridSearch` wrapper from `tpcp`.\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.exceptions import NotFittedError\n",
    "from gaitlink.data_transform import ButterworthFilter\n",
    "\n",
    "class UllrichLRDetection(BaseLRDetection):\n",
    "    # ARNE: Having this here is just for convenience -> This way users don't need to import another thing, but can just do UllrichLRDetection.PRETRAINED_MODEL. ... to get the models.\n",
    "    PRETRAINED_MODEL = PretrainedModel # why is this here???\n",
    "    \n",
    "    def __init__(self, model: Union[PretrainedModel, ClassifierMixin] = PretrainedModel.svm_linear): # ok, so the default model is model_1\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        # I don't really think that additional parameters are required here. If you are using a pretrained model, then you should not be able to change the model, i.e. you should not provide a model parameter separately.\n",
    "        # also, sklearn models can be assigned with different parameters after initialization using the _set_params method. Then you can just provide a dictionary of the required parameters.\n",
    "        # self.param_1 = param_1\n",
    "        # self.param_2 = param_2...\n",
    "\n",
    "\n",
    "        # ARNE: Move the model check into the action method. \n",
    "        # ALEX: I think that this should actually be here, since PretrainedModel class does not have any set_params methods, users might attempt to change hyperparameters before doing anything else.\n",
    "        # self.model = self._check_and_init_model(self.model)\n",
    "\n",
    "\n",
    "    # ARNE: No need for that.\n",
    "    # UllrichLRDetection.set_params(model__para_name=c) does the same thing. You just need to prefix all parameters with `model__`\n",
    "    # def _set_params(self, param_dict: dict):\n",
    "    #     \"\"\"\n",
    "    #     Set the parameters of the model.\n",
    "    #     \"\"\"\n",
    "    #     self.model.set_params(**param_dict)\n",
    "    #     return self\n",
    "    \n",
    "    @staticmethod\n",
    "    def _check_and_init_model(model):\n",
    "        \"\"\"\n",
    "        This is an utility function for checking the type of the given model and initializing it, if it is a PretrainedModel.\n",
    "        If the model is an instance of ClassifierMixin, it simply returns the model.\n",
    "        If the model is not an instance of either PretrainedModel or ClassifierMixin, it raises a TypeError.\n",
    "\n",
    "        Parameters:\n",
    "        model (PretrainedModel or ClassifierMixin): The model to check and possibly initialize.\n",
    "\n",
    "        Returns:\n",
    "        model (ClassifierMixin): The checked and possibly initialized model.\n",
    "\n",
    "        Raises:\n",
    "        TypeError: If the model is not an instance of either PretrainedModel or ClassifierMixin.\n",
    "        \"\"\"\n",
    "        print('Model checking...')\n",
    "        if isinstance(model, PretrainedModel):\n",
    "            model = PretrainedModel.load_pretrained_model(model.value)\n",
    "        if isinstance(model, ClassifierMixin):\n",
    "            return model\n",
    "        raise TypeError(f\"Unknown model type {type(model)}. The model must be of type {PretrainedModel} or {ClassifierMixin}\")\n",
    "    \n",
    "    # ARNE: sampling_rate -> sampling_rate_hz\n",
    "    def detect(self, data: pd.DataFrame, ics: pd.Series, sampling_rate_hz: float = 100):\n",
    "        \"\"\"\n",
    "        This function applies the model to the provided data to make predictions. \n",
    "\n",
    "        Parameters:\n",
    "        data (pd.DataFrame): A dataframe representing data from a GS.\n",
    "        ics (pd.Series): A series representing a list of ICs within a GS, 0-index at the start of the GS.\n",
    "        sampling_rate_hz (float, optional): The sampling rate in Hz. Defaults to 100.\n",
    "\n",
    "        Returns:\n",
    "        self: The instance of the class with the predictions stored in the ic_lr attribute.\n",
    "\n",
    "        Raises:\n",
    "        RuntimeError: If the model is not fitted.\n",
    "        \"\"\"\n",
    "        # Alex: I do not agree that we should be providing data and ics as instances of this class. They should be kept independent and only be called when fitting the model or when predicting. Other than that, we do not need to drag them around.\n",
    "        self.sampling_rate_hz = sampling_rate_hz\n",
    "        self.data = data\n",
    "        self.ics = ics\n",
    "\n",
    "        self.model = self._check_and_init_model(self.model)\n",
    "\n",
    "        model = self.model\n",
    "        \n",
    "        try:\n",
    "            check_is_fitted(model)\n",
    "        except NotFittedError:\n",
    "            raise RuntimeError(\"Model is not fitted. Call self_optimize before calling detect.\")\n",
    "        \n",
    "        # preprocess data\n",
    "        # TODO: for consistency, you might want to export a data frame here as well\n",
    "        processed_data = self.extract_features(data, ics, sampling_rate_hz)\n",
    "        \n",
    "        # ALEX: It might be more elegant to only return the value of the prediction and nothing else.\n",
    "        self.ic_lr = model.predict(processed_data)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    # ARNE: sampling_rate -> sampling_rate_hz\n",
    "    def self_optimize(self, data: list[pd.DataFrame], ic_list: list[pd.Series], label_list: list[pd.Series], sampling_rate_hz: float = 100):\n",
    "        \"\"\"\n",
    "        This function optimizes the model by fitting it on the provided data.\n",
    "\n",
    "        Parameters:\n",
    "        data (list[pd.DataFrame]): List of dataframes, each representing data from a GS. Data from multiple GSs is preferred as it results in a larger feature set.\n",
    "        ic_list (list[pd.Series]): List of series, each representing a list of ICs within a GS, with sample 0 as the start of GS.\n",
    "        label_list (list[pd.Series]): List of series, each representing a list of IC labels.\n",
    "        sampling_rate_hz (float, optional): The sampling rate in Hz. Defaults to 100.\n",
    "\n",
    "        Returns:\n",
    "        self: The instance of the class with the optimized model.\n",
    "\n",
    "        Raises:\n",
    "        Exception: If there is an error during the concatenation of features or labels.\n",
    "        \"\"\"\n",
    "        # data: data from either one GS, or for a list of all GSs. The latter is preferred, as it will results in a bigger feature set.\n",
    "        # ic_list: a list of lists of ICs within a GS, sample 0 start of GS\n",
    "        # label_list: a list of IC labels\n",
    "        \n",
    "        model = self.model\n",
    "\n",
    "        # ARNE: I am not a big fan of doing convenience conversion. I would suggest to check if it is a list and force the user to make the conversion\n",
    "        # ALEX: ok, I'll change that.\n",
    "        if not isinstance(data, list):\n",
    "            raise TypeError(\"data must be a list\")\n",
    "            \n",
    "        if not isinstance(ic_list, list):\n",
    "            raise TypeError(\"ic_list must be a list\")\n",
    "        \n",
    "        # preprocess data\n",
    "        features = []\n",
    "        for gs in range(len(data)):\n",
    "            features.append(self.extract_features(data[gs], ic_list[gs], sampling_rate_hz))\n",
    "\n",
    "        # ARNE: What is the logic here? Do you need the except, if there is only 1 GS? If yes make that check explicit\n",
    "        # ALEX: this has designed to handle both single and multiple GSs. if you really want to optimize your model, then you should provide a list of GSs (the more data, the better). However, if they only provide one GS, then it will still work. (normally it will fail during concatenation).\n",
    "        try:    \n",
    "            all_features = pd.concat(features, axis = 0, ignore_index = True)\n",
    "        except:\n",
    "            all_features = features\n",
    "            \n",
    "        try:\n",
    "            all_labels = pd.concat(label_list, axis = 0, ignore_index = True)\n",
    "        except:\n",
    "            \n",
    "            all_labels = label_list\n",
    "        \n",
    "        self.model = model.fit(all_features, all_labels)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def extract_features(self, data, ics, sampling_rate_hz):\n",
    "        \"\"\"\n",
    "        This function extracts features from the provided data. These are the filtered vertical and anterior-posterior angular velocity, plus their first and second derivative @ the location of the detected initial contacts.\n",
    "\n",
    "        Parameters:\n",
    "        data (pd.DataFrame): A dataframe representing data from a GS.\n",
    "        ics (pd.Series): A corresponding series representing the initial contacts per GS.\n",
    "        sampling_rate_hz (float): The signal sampling rate.\n",
    "\n",
    "        Returns:\n",
    "        feature_df (pd.DataFrame): A dataframe containing the extracted features.\n",
    "\n",
    "        Note:\n",
    "        The function currently uses fixed lower and upper bands for the Butterworth filter. \n",
    "        These parameters should be exposed in the future to allow for more flexibility. \n",
    "        The function also currently shifts the last IC by 3 samples to make the second derivative work. \n",
    "        This approach may need to be revised in the future.\n",
    "        \"\"\"\n",
    "\n",
    "        # ARNE: We should probably expose these parameters, but than we also need to \"store\" them together with the pretrained models, as the models are specific to the preprocssing paras.\n",
    "        #       -> We need to think about a good way to store models and other parameters together. I will come up with something\n",
    "        lower_band = 0.5\n",
    "        upper_band = 2\n",
    "        # TODO: find a way of exposing these filtering parameters..\n",
    "\n",
    "        # Apply Butterworth filtering and extract the first and second derivatives.\n",
    "        butter_filter = ButterworthFilter(order=4, cutoff_freq_hz=(lower_band, upper_band), filter_type=\"bandpass\")\n",
    "        \n",
    "        gyr = data[[\"gyr_x\", \"gyr_z\"]].rename({\"gyr_x\": \"v\", \"gyr_z\": \"ap\"})\n",
    "        gyr_filtered = butter_filter.filter(gyr, sampling_rate_hz = sampling_rate_hz).filtered_data_\n",
    "        gyr_diff = gyr_filtered.diff()\n",
    "        gyr_diff_2 = gyr_diff.diff()\n",
    "        signal_paras = pd.concat({\"filtered\": gyr_filtered, \"gradient\": gyr_diff, \"diff_2\": gyr_diff_2}, axis=1)\n",
    "        # Squash the multi index\n",
    "        signal_paras.columns = [\"_\".join(c) for c in signal_paras.columns]\n",
    "\n",
    "        ics -= 1\n",
    "        # shift the last IC by 3 samples to make the second derivative work\n",
    "        ics[ics < 2] = 2\n",
    "\n",
    "        feature_df = signal_paras.loc[ics['ic'].values.tolist()]\n",
    "  \n",
    "        \n",
    "        return feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is option 1, loading a pretrained model, but how about specifying a custom model?\n",
    "# my_algo = UllrichLRDetection(model = PretrainedModel.svm_linear)\n",
    "\n",
    "# this is option 2, specifying a custom model.\n",
    "# my_algo = UllrichLRDetection(model = neighbors.KNeighborsClassifier(n_neighbors = 3))\n",
    "my_algo = UllrichLRDetection(model = svm.SVC())\n",
    "\n",
    "# Note that all models must be sklearn models for this to work.\n",
    "\n",
    "# TODO: when using pre-trained models, the following inconsistency warning is expected: InconsistentVersionWarning: Trying to unpickle estimator SVC from version 0.23.1 when using version 1.3.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
    "# TODO: How can we avoid this?\n",
    "my_algo.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How ca we change model's hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=25, gamma=0.002)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=25, gamma=0.002)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=25, gamma=0.002)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how you might change hyperparameters, nothing that this only works when using custom models.\n",
    "# For PretrainedModels, this will only work once an action method has been triggered (i.e. my_algo.detect), which is expected, as users should not attempt changing pretrained models hyperparameters.\n",
    "\n",
    "my_algo.set_params(model__C=25, model__gamma=0.002)\n",
    "\n",
    "# Or\n",
    "# my_paras = {'model__C': 25, 'model__gamma': 0.002, 'model__kernel': 'linear'}\n",
    "# my_algo.set_params(**my_paras)\n",
    "\n",
    "my_algo.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How can we get the model's hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 25,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 0.002,\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_algo.model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': 25,\n",
       " 'model__break_ties': False,\n",
       " 'model__cache_size': 200,\n",
       " 'model__class_weight': None,\n",
       " 'model__coef0': 0.0,\n",
       " 'model__decision_function_shape': 'ovr',\n",
       " 'model__degree': 3,\n",
       " 'model__gamma': 0.002,\n",
       " 'model__kernel': 'rbf',\n",
       " 'model__max_iter': -1,\n",
       " 'model__probability': False,\n",
       " 'model__random_state': None,\n",
       " 'model__shrinking': True,\n",
       " 'model__tol': 0.001,\n",
       " 'model__verbose': False,\n",
       " 'model': SVC(C=25, gamma=0.002)}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARNE: another option might be:\n",
    "my_algo.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the model for L/R detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Model is not fitted. Call self_optimize before calling detect.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 73\u001b[0m, in \u001b[0;36mUllrichLRDetection.detect\u001b[0;34m(self, data, ics, sampling_rate_hz)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError:\n",
      "File \u001b[0;32m~/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1461\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1461\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This SVC instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmy_algo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m               \u001b[49m\u001b[43mics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mic_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m               \u001b[49m\u001b[43msampling_rate_hz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msampling_rate_hz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# this will throw an error, because the model is not fitted yet.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 75\u001b[0m, in \u001b[0;36mUllrichLRDetection.detect\u001b[0;34m(self, data, ics, sampling_rate_hz)\u001b[0m\n\u001b[1;32m     73\u001b[0m     check_is_fitted(model)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel is not fitted. Call self_optimize before calling detect.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# preprocess data\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# TODO: for consistency, you might want to export a data frame here as well\u001b[39;00m\n\u001b[1;32m     79\u001b[0m processed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_features(data, ics, sampling_rate_hz)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Model is not fitted. Call self_optimize before calling detect."
     ]
    }
   ],
   "source": [
    "my_algo.detect(data = data_list[0],\n",
    "               ics = ic_list[0],\n",
    "               sampling_rate_hz = sampling_rate_hz)\n",
    "\n",
    "# this will throw an error, because the model is not fitted yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexstihi/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UllrichLRDetection(model=SVC(C=25, gamma=0.002))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "my_algo.self_optimize(data = data_list,\n",
    "                      ic_list = ic_list,\n",
    "                      label_list = label_list,\n",
    "                      sampling_rate_hz = sampling_rate_hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checking...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UllrichLRDetection(model=SVC(C=25, gamma=0.002))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_algo.detect(data = data_list[0], ics = ic_list[0], sampling_rate_hz = sampling_rate_hz)\n",
    "# ok, so this seems to be working now...\n",
    "# an alternative way would be to either do the processing before feeding the data_list above across all walking bouts, or allowing a list the be handled directly in the method, as in self_optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Left', 'Right', 'Left', 'Right', 'Left', 'Right', 'Left'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_algo.ic_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_lr_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predicted_lr_label\n",
       "0               Left\n",
       "1              Right\n",
       "2               Left\n",
       "3              Right\n",
       "4               Left\n",
       "5              Right\n",
       "6               Left"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_algo.ic_lr # maybe this should be put into a DF, for consistency?\n",
    "result_name = [\"predicted_lr_label\"]\n",
    "results = pd.DataFrame(my_algo.ic_lr, columns = result_name)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Left</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lr_label\n",
       "0     Left\n",
       "1    Right\n",
       "2     Left\n",
       "3    Right\n",
       "4     Left\n",
       "5    Right\n",
       "6     Left"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the results\n",
    "label_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we optimize the model, using grid search?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4 style=\"margin-bottom: 0.1em;\">LabExampleDataset [2 groups/rows]</h3>\n",
       "<div style=\"margin-top: 0em\">\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table style=\"margin-left: 3em;\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th style=\"text-align: center;\"></th>\n",
       "      <th style=\"text-align: center;\">cohort</th>\n",
       "      <th style=\"text-align: center;\">participant_id</th>\n",
       "      <th style=\"text-align: center;\">time_measure</th>\n",
       "      <th style=\"text-align: center;\">test</th>\n",
       "      <th style=\"text-align: center;\">trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th style=\"text-align: center;\">0</th>\n",
       "      <td style=\"text-align: center; padding-left: 2em; padding-right: 2em;\">HA</td>\n",
       "      <td style=\"text-align: center; padding-left: 2em; padding-right: 2em;\">001</td>\n",
       "      <td style=\"text-align: center; padding-left: 2em; padding-right: 2em;\">TimeMeasure1</td>\n",
       "      <td style=\"text-align: center; padding-left: 2em; padding-right: 2em;\">Test11</td>\n",
       "      <td style=\"text-align: center; padding-left: 2em; padding-right: 2em;\">Trial1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th style=\"text-align: center;\">1</th>\n",
       "      <td style=\"text-align: center; padding-left: 2em; padding-right: 2em;\">HA</td>\n",
       "      <td style=\"text-align: center; padding-left: 2em; padding-right: 2em;\">002</td>\n",
       "      <td style=\"text-align: center; padding-left: 2em; padding-right: 2em;\">TimeMeasure1</td>\n",
       "      <td style=\"text-align: center; padding-left: 2em; padding-right: 2em;\">Test11</td>\n",
       "      <td style=\"text-align: center; padding-left: 2em; padding-right: 2em;\">Trial1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "LabExampleDataset [2 groups/rows]\n",
       "\n",
       "     cohort participant_id  time_measure    test   trial\n",
       "   0     HA            001  TimeMeasure1  Test11  Trial1\n",
       "   1     HA            002  TimeMeasure1  Test11  Trial1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ARNE:\n",
    "# This is a trainable model -> GridSearchCV (or custom Optuna Optimizer with internace CV)\n",
    "# Optimization in tpcp only works with Pipelines not with algorithms (https://tpcp.readthedocs.io/en/latest/guides/algorithms_pipelines_datasets.html#pipelines)\n",
    "# -> we need wrapper around dataset and Algorithm\n",
    "#\n",
    "# Dataset we already have for the example data (other data could be loaded with `GenericMobilisedDataset`)\n",
    "from gaitlink.data import LabExampleDataset\n",
    "\n",
    "dataset = LabExampleDataset(reference_system=\"INDIP\").get_subset(cohort=\"HA\", test=\"Test11\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper -> we should probably move something like this into the data loader itself\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_ref_data(imu_data, ref_walking_bouts):\n",
    "\n",
    "    data_list = []\n",
    "    ic_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for gs in range(len(ref_walking_bouts)):\n",
    "        gs_start = ref_walking_bouts.iloc[gs].start\n",
    "        gs_end = ref_walking_bouts.iloc[gs].end\n",
    "        \n",
    "        data_list.append(imu_data.iloc[gs_start : gs_end].reset_index(drop = True))\n",
    "        ic_list.append(ref_ics.loc[ref_ics.index.get_level_values('wb_id') == gs + 1, ['ic']].reset_index(drop = True) - gs_start) \n",
    "        label_list.append(ref_ics.loc[ref_ics.index.get_level_values('wb_id') == gs + 1, ['lr_label']].reset_index(drop = True))\n",
    "    \n",
    "    return data_list, ic_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReferenceData(walking_bouts=       start    end  n_strides  duration_s  length_m  avg_speed_mps  \\\n",
       "wb_id                                                                 \n",
       "1        633    988          5        3.55  3.428989       0.975373   \n",
       "2       2865   3325          4        4.60  1.452572       0.411857   \n",
       "3       3854   5085         16       12.31  7.044042       0.617801   \n",
       "4       7642   8621         12        9.79  4.396574       0.510108   \n",
       "5       9452   9932          6        4.80  3.545277       0.755728   \n",
       "6      11990  12517          6        5.27  3.514735       0.880632   \n",
       "\n",
       "       avg_cadence_spm  avg_stride_length_m termination_reason  \n",
       "wb_id                                                           \n",
       "1           104.069084             1.124391              Pause  \n",
       "2            81.296475             0.581029              Pause  \n",
       "3            89.246331             0.838960              Pause  \n",
       "4            94.370318             0.645176              Pause  \n",
       "5            88.778698             1.021695              Pause  \n",
       "6            95.832693             1.021576              Pause  , initial_contacts=                ic lr_label\n",
       "wb_id ic_id                \n",
       "1     0        633     Left\n",
       "      1        710    Right\n",
       "      2        764     Left\n",
       "      3        825    Right\n",
       "      4        877     Left\n",
       "...            ...      ...\n",
       "6     58     12163     Left\n",
       "      59     12221    Right\n",
       "      60     12278     Left\n",
       "      61     12336    Right\n",
       "      62     12517     Left\n",
       "\n",
       "[63 rows x 2 columns], turn_parameters=                start     end  duration_s   angle_deg\n",
       "wb_id turn_id                                        \n",
       "3.0   0         45.13   45.64        0.51  -55.541164\n",
       "      1         45.64   48.03        2.39   89.769146\n",
       "4.0   2         77.47   81.11        3.64 -132.791232\n",
       "      3         84.16   86.21        2.05   88.004630\n",
       "6.0   4        122.91  123.69        0.78  -80.196002\n",
       "      5        123.69  124.42        0.73   46.222801\n",
       "      6        124.42  125.17        0.75  -50.326478, stride_parameters=            start    end  duration_s  length_m  speed_mps  stance_time_s  \\\n",
       "wb_id s_id                                                                 \n",
       "1     0       633    764        1.31  1.083254   0.826911           1.01   \n",
       "      1       710    825        1.15  1.135652   0.987523           0.77   \n",
       "      2       764    877        1.13  1.308362   1.157843           0.83   \n",
       "      3       825    934        1.09  1.057317   0.970016           0.75   \n",
       "      4       877    988        1.11  1.037373   0.934570           0.80   \n",
       "2     5      2865   2997        1.32  1.148344   0.869957           0.94   \n",
       "      6      2936   3059        1.23  0.580631   0.472058           0.87   \n",
       "      7      2997   3128        1.31  0.210824   0.160934           0.99   \n",
       "      8      3059   3325        2.66  0.384317   0.144480           2.46   \n",
       "3     9      3854   3981        1.27  1.013344   0.797909           0.94   \n",
       "      10     3923   4083        1.60  0.210917   0.131823           0.81   \n",
       "      11     3981   4147        1.66  1.079405   0.650244           1.18   \n",
       "      12     4083   4214        1.31  0.945297   0.721601           0.87   \n",
       "      13     4147   4346        1.99  0.366200   0.184020           1.03   \n",
       "      14     4214   4435        2.21  1.024790   0.463706           1.73   \n",
       "      15     4346   4495        1.49  1.260213   0.845781           1.13   \n",
       "      16     4435   4569        1.34  1.291307   0.963662           0.81   \n",
       "      17     4495   4637        1.42  0.913999   0.643661           0.98   \n",
       "      18     4569   4701        1.32  0.514269   0.389598           0.92   \n",
       "      19     4637   4763        1.26  0.898366   0.712989           0.91   \n",
       "      20     4701   4818        1.17  0.966838   0.826357           0.88   \n",
       "      21     4763   4863        1.00  0.927393   0.927393           0.76   \n",
       "      22     4818   4910        0.92  0.576360   0.626479           0.66   \n",
       "      23     4863   4965        1.02  0.439632   0.431012           0.72   \n",
       "      24     4910   5085        1.75  0.995023   0.568584           0.87   \n",
       "4     25     7642   7791        1.49  0.234114   0.157123           1.18   \n",
       "      26     7643   7853        2.10  0.204737   0.097494           1.79   \n",
       "      27     7791   7899        1.08  0.322767   0.298858           0.75   \n",
       "      28     7853   8045         NaN       NaN        NaN            NaN   \n",
       "      29     7899   7992        0.93  0.376819   0.405181           0.66   \n",
       "      30     7992   8096         NaN       NaN        NaN            NaN   \n",
       "      31     8045   8168        1.23  0.618273   0.502661           0.88   \n",
       "      32     8096   8229        1.33  0.646473   0.486070           0.89   \n",
       "      33     8168   8284        1.16  0.679662   0.585916           0.90   \n",
       "      34     8229   8342        1.13  0.761896   0.674244           0.80   \n",
       "      35     8284   8404        1.20  1.045320   0.871100           0.81   \n",
       "      36     8342   8473        1.31  1.058517   0.808028           0.87   \n",
       "      37     8404   8546        1.42  0.797550   0.561655           0.98   \n",
       "      38     8473   8621        1.48  0.995989   0.672966           0.99   \n",
       "5     39     9452   9602        1.50  0.970735   0.647157           1.10   \n",
       "      40     9536   9664        1.28  1.032149   0.806367           0.90   \n",
       "      41     9602   9735        1.33  1.111873   0.835994           0.89   \n",
       "      42     9664   9800        1.36  1.176755   0.865261           0.97   \n",
       "      43     9735   9869        1.34  1.179048   0.879887           0.91   \n",
       "      44     9800   9932        1.32  0.659609   0.499704           0.99   \n",
       "6     45    11990  12109        1.19  1.251168   1.051401           0.85   \n",
       "      46    12052  12163        1.11  1.255000   1.130631           0.78   \n",
       "      47    12109  12221        1.12  1.305096   1.165265           0.75   \n",
       "      48    12163  12278        1.15  1.224294   1.064603           0.80   \n",
       "      49    12221  12336        1.15  0.918078   0.798329           0.81   \n",
       "      50    12278  12517        2.39  0.175817   0.073564           2.28   \n",
       "\n",
       "            swing_time_s lr_label  \n",
       "wb_id s_id                         \n",
       "1     0             0.30     Left  \n",
       "      1             0.38    Right  \n",
       "      2             0.30     Left  \n",
       "      3             0.34    Right  \n",
       "      4             0.31     Left  \n",
       "2     5             0.38    Right  \n",
       "      6             0.36     Left  \n",
       "      7             0.32    Right  \n",
       "      8             0.20     Left  \n",
       "3     9             0.33     Left  \n",
       "      10            0.79    Right  \n",
       "      11            0.48     Left  \n",
       "      12            0.44    Right  \n",
       "      13            0.96     Left  \n",
       "      14            0.48    Right  \n",
       "      15            0.36     Left  \n",
       "      16            0.53    Right  \n",
       "      17            0.44     Left  \n",
       "      18            0.40    Right  \n",
       "      19            0.35     Left  \n",
       "      20            0.29    Right  \n",
       "      21            0.24     Left  \n",
       "      22            0.26    Right  \n",
       "      23            0.30     Left  \n",
       "      24            0.88    Right  \n",
       "4     25            0.31    Right  \n",
       "      26            0.31     Left  \n",
       "      27            0.33    Right  \n",
       "      28             NaN     Left  \n",
       "      29            0.27    Right  \n",
       "      30             NaN    Right  \n",
       "      31            0.35     Left  \n",
       "      32            0.44    Right  \n",
       "      33            0.26     Left  \n",
       "      34            0.33    Right  \n",
       "      35            0.39     Left  \n",
       "      36            0.44    Right  \n",
       "      37            0.44     Left  \n",
       "      38            0.49    Right  \n",
       "5     39            0.40    Right  \n",
       "      40            0.38     Left  \n",
       "      41            0.44    Right  \n",
       "      42            0.39     Left  \n",
       "      43            0.43    Right  \n",
       "      44            0.33     Left  \n",
       "6     45            0.34    Right  \n",
       "      46            0.33     Left  \n",
       "      47            0.37    Right  \n",
       "      48            0.35     Left  \n",
       "      49            0.34    Right  \n",
       "      50            0.11     Left  )"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>n_strides</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>length_m</th>\n",
       "      <th>avg_speed_mps</th>\n",
       "      <th>avg_cadence_spm</th>\n",
       "      <th>avg_stride_length_m</th>\n",
       "      <th>termination_reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wb_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633</td>\n",
       "      <td>988</td>\n",
       "      <td>5</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.428989</td>\n",
       "      <td>0.975373</td>\n",
       "      <td>104.069084</td>\n",
       "      <td>1.124391</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2865</td>\n",
       "      <td>3325</td>\n",
       "      <td>4</td>\n",
       "      <td>4.60</td>\n",
       "      <td>1.452572</td>\n",
       "      <td>0.411857</td>\n",
       "      <td>81.296475</td>\n",
       "      <td>0.581029</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3854</td>\n",
       "      <td>5085</td>\n",
       "      <td>16</td>\n",
       "      <td>12.31</td>\n",
       "      <td>7.044042</td>\n",
       "      <td>0.617801</td>\n",
       "      <td>89.246331</td>\n",
       "      <td>0.838960</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7642</td>\n",
       "      <td>8621</td>\n",
       "      <td>12</td>\n",
       "      <td>9.79</td>\n",
       "      <td>4.396574</td>\n",
       "      <td>0.510108</td>\n",
       "      <td>94.370318</td>\n",
       "      <td>0.645176</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9452</td>\n",
       "      <td>9932</td>\n",
       "      <td>6</td>\n",
       "      <td>4.80</td>\n",
       "      <td>3.545277</td>\n",
       "      <td>0.755728</td>\n",
       "      <td>88.778698</td>\n",
       "      <td>1.021695</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11990</td>\n",
       "      <td>12517</td>\n",
       "      <td>6</td>\n",
       "      <td>5.27</td>\n",
       "      <td>3.514735</td>\n",
       "      <td>0.880632</td>\n",
       "      <td>95.832693</td>\n",
       "      <td>1.021576</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       start    end  n_strides  duration_s  length_m  avg_speed_mps  \\\n",
       "wb_id                                                                 \n",
       "1        633    988          5        3.55  3.428989       0.975373   \n",
       "2       2865   3325          4        4.60  1.452572       0.411857   \n",
       "3       3854   5085         16       12.31  7.044042       0.617801   \n",
       "4       7642   8621         12        9.79  4.396574       0.510108   \n",
       "5       9452   9932          6        4.80  3.545277       0.755728   \n",
       "6      11990  12517          6        5.27  3.514735       0.880632   \n",
       "\n",
       "       avg_cadence_spm  avg_stride_length_m termination_reason  \n",
       "wb_id                                                           \n",
       "1           104.069084             1.124391              Pause  \n",
       "2            81.296475             0.581029              Pause  \n",
       "3            89.246331             0.838960              Pause  \n",
       "4            94.370318             0.645176              Pause  \n",
       "5            88.778698             1.021695              Pause  \n",
       "6            95.832693             1.021576              Pause  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_walking_bouts = ref_data.walking_bouts\n",
    "ref_walking_bouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how can we make the pipeline optimization handle a list of dataframes?\n",
    "\n",
    "dp = 0\n",
    "datapoint = dataset[dp]\n",
    "\n",
    "imu_data = datapoint.data[\"LowerBack\"]\n",
    "ref_data = datapoint.reference_parameters_\n",
    "ref_walking_bouts = ref_data.walking_bouts\n",
    "\n",
    "gs_data, ics, labels = extract_ref_data(imu_data, ref_walking_bouts)\n",
    "\n",
    "# once you have the gs_data, ics and labels, then you can simply run the optimization on the ML algo itself, by doing my_algo.self_optimize(gs_data, ics, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline we need to build, but this is relativly easy\n",
    "from tpcp import OptimizablePipeline, OptimizableParameter\n",
    "\n",
    "class LROptiPipeline(OptimizablePipeline):\n",
    "    # This is a trick we use internally to check that the optimization is not doing something strange.\n",
    "    # Only the model is allowed to change. If other things change, we get an error by default.\n",
    "    algo__model: OptimizableParameter\n",
    "\n",
    "    algo_with_results_: UllrichLRDetection\n",
    "\n",
    "    # A couple of ways to do the parameters here, the easiest is that (just requires a little bit annoying prefix nesting)\n",
    "    def __init__(self, algo):\n",
    "        self.algo = algo\n",
    "\n",
    "    @property\n",
    "    def ic_lr_(self):\n",
    "        return self.algo_with_results_.ic_lr\n",
    "\n",
    "    def run(self, dp):\n",
    "        # Here, dp might just be a single datapoint\n",
    "        \n",
    "        imu_data = dp.data[\"LowerBack\"]\n",
    "        ref_data = dp.reference_parameters_\n",
    "        ref_walking_bouts = ref_data.walking_bouts\n",
    "\n",
    "        # if not isinstance(ref_walking_bouts, list):\n",
    "        #     ref_walking_bouts = [ref_walking_bouts]\n",
    "        gs_data, ics, _ = extract_ref_data(imu_data, ref_walking_bouts)\n",
    "        # We just run this with the first GS here, but we could add a loop to handle multiple GS\n",
    "        self.algo_with_results_ = self.algo.clone().detect(gs_data[0], ics[0], dp.sampling_rate_hz)\n",
    "        return self\n",
    "\n",
    "    def self_optimize(self, ds):\n",
    "        # ds = dataset\n",
    "        # Here we get a full dataset -> I.e. multiple datapoints\n",
    "        sampling_rate_hz = ds[0].sampling_rate_hz\n",
    "        \n",
    "        all_gs_data = []\n",
    "        all_ics = []\n",
    "        all_labels = []\n",
    "        for dp in ds:\n",
    "            # dp = datapoint\n",
    "\n",
    "            imu_data = dp.data[\"LowerBack\"]\n",
    "            ref_data = dp.reference_parameters_\n",
    "            ref_walking_bouts = ref_data.walking_bouts\n",
    "\n",
    "            # if not isinstance(ref_walking_bouts, list):\n",
    "            #     ref_walking_bouts = [ref_walking_bouts]\n",
    "            gs_data, ics, labels = extract_ref_data(imu_data, ref_walking_bouts)\n",
    "            \n",
    "            all_gs_data.extend(gs_data) # I haven't used this extend method before.\n",
    "            all_ics.extend(ics)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "        # No cloning here -> We actually want to modify the object\n",
    "        # this is the self_optimize method of the algorithm, not for the pipeline\n",
    "        self.algo.self_optimize(all_gs_data, all_ics, all_labels)\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just testing the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexstihi/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Left', 'Right', 'Left', 'Right', 'Left', 'Right', 'Left'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = LROptiPipeline(UllrichLRDetection(model=svm.SVC()))\n",
    "pipe.self_optimize(dataset)\n",
    "pipe.run(dataset[0]).ic_lr_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>n_strides</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>length_m</th>\n",
       "      <th>avg_speed_mps</th>\n",
       "      <th>avg_cadence_spm</th>\n",
       "      <th>avg_stride_length_m</th>\n",
       "      <th>termination_reason</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wb_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633</td>\n",
       "      <td>988</td>\n",
       "      <td>5</td>\n",
       "      <td>3.55</td>\n",
       "      <td>3.428989</td>\n",
       "      <td>0.975373</td>\n",
       "      <td>104.069084</td>\n",
       "      <td>1.124391</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2865</td>\n",
       "      <td>3325</td>\n",
       "      <td>4</td>\n",
       "      <td>4.60</td>\n",
       "      <td>1.452572</td>\n",
       "      <td>0.411857</td>\n",
       "      <td>81.296475</td>\n",
       "      <td>0.581029</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3854</td>\n",
       "      <td>5085</td>\n",
       "      <td>16</td>\n",
       "      <td>12.31</td>\n",
       "      <td>7.044042</td>\n",
       "      <td>0.617801</td>\n",
       "      <td>89.246331</td>\n",
       "      <td>0.838960</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7642</td>\n",
       "      <td>8621</td>\n",
       "      <td>12</td>\n",
       "      <td>9.79</td>\n",
       "      <td>4.396574</td>\n",
       "      <td>0.510108</td>\n",
       "      <td>94.370318</td>\n",
       "      <td>0.645176</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9452</td>\n",
       "      <td>9932</td>\n",
       "      <td>6</td>\n",
       "      <td>4.80</td>\n",
       "      <td>3.545277</td>\n",
       "      <td>0.755728</td>\n",
       "      <td>88.778698</td>\n",
       "      <td>1.021695</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11990</td>\n",
       "      <td>12517</td>\n",
       "      <td>6</td>\n",
       "      <td>5.27</td>\n",
       "      <td>3.514735</td>\n",
       "      <td>0.880632</td>\n",
       "      <td>95.832693</td>\n",
       "      <td>1.021576</td>\n",
       "      <td>Pause</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       start    end  n_strides  duration_s  length_m  avg_speed_mps  \\\n",
       "wb_id                                                                 \n",
       "1        633    988          5        3.55  3.428989       0.975373   \n",
       "2       2865   3325          4        4.60  1.452572       0.411857   \n",
       "3       3854   5085         16       12.31  7.044042       0.617801   \n",
       "4       7642   8621         12        9.79  4.396574       0.510108   \n",
       "5       9452   9932          6        4.80  3.545277       0.755728   \n",
       "6      11990  12517          6        5.27  3.514735       0.880632   \n",
       "\n",
       "       avg_cadence_spm  avg_stride_length_m termination_reason  \n",
       "wb_id                                                           \n",
       "1           104.069084             1.124391              Pause  \n",
       "2            81.296475             0.581029              Pause  \n",
       "3            89.246331             0.838960              Pause  \n",
       "4            94.370318             0.645176              Pause  \n",
       "5            88.778698             1.021695              Pause  \n",
       "6            95.832693             1.021576              Pause  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].reference_parameters_.walking_bouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a Gridsearch we need one more thing: A scorer.\n",
    "# In tpcp, as we have a general case, we always need to write our own scorer function\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def scoring(pipe, dp):\n",
    "    pipe = pipe.safe_run(dp)\n",
    "    _, _, labels = extract_ref_data(dp.data[\"LowerBack\"], dp.reference_parameters_.walking_bouts)\n",
    "    return {\"accuracy\": accuracy_score(labels[0].to_numpy(), pipe.ic_lr_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the scorer\n",
    "scoring(pipe, dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__model__C': 1.0,\n",
       " 'algo__model__break_ties': False,\n",
       " 'algo__model__cache_size': 200,\n",
       " 'algo__model__class_weight': None,\n",
       " 'algo__model__coef0': 0.0,\n",
       " 'algo__model__decision_function_shape': 'ovr',\n",
       " 'algo__model__degree': 3,\n",
       " 'algo__model__gamma': 'scale',\n",
       " 'algo__model__kernel': 'rbf',\n",
       " 'algo__model__max_iter': -1,\n",
       " 'algo__model__probability': False,\n",
       " 'algo__model__random_state': None,\n",
       " 'algo__model__shrinking': True,\n",
       " 'algo__model__tol': 0.001,\n",
       " 'algo__model__verbose': False,\n",
       " 'algo__model': SVC(),\n",
       " 'algo': UllrichLRDetection(model=SVC())}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexstihi/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Split-Para Combos:   0%|          | 0/6 [00:00<?, ?it/s]/Users/alexstihi/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "Datapoints: 100%|██████████| 1/1 [00:00<00:00,  8.43it/s]\n",
      "Split-Para Combos:  17%|█▋        | 1/6 [00:00<00:01,  5.00it/s]/Users/alexstihi/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "Datapoints: 100%|██████████| 1/1 [00:00<00:00, 10.62it/s]\n",
      "Split-Para Combos:  33%|███▎      | 2/6 [00:00<00:00,  5.31it/s]/Users/alexstihi/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "Datapoints: 100%|██████████| 1/1 [00:00<00:00,  8.75it/s]\n",
      "Split-Para Combos:  50%|█████     | 3/6 [00:00<00:00,  5.36it/s]/Users/alexstihi/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "Datapoints: 100%|██████████| 1/1 [00:00<00:00,  9.84it/s]\n",
      "Split-Para Combos:  67%|██████▋   | 4/6 [00:00<00:00,  5.31it/s]/Users/alexstihi/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "Datapoints: 100%|██████████| 1/1 [00:00<00:00,  8.67it/s]\n",
      "Split-Para Combos:  83%|████████▎ | 5/6 [00:00<00:00,  5.31it/s]/Users/alexstihi/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "Datapoints: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s]\n",
      "Split-Para Combos: 100%|██████████| 6/6 [00:01<00:00,  5.29it/s]\n",
      "/Users/alexstihi/Documents/PhD_Repos/Mobilize_D/gaitlink/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from tpcp.optimize import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Note: the deep nesting of the paras here. This is a little arkward, but hey\n",
    "para_grid = ParameterGrid({\n",
    "    \"algo__model__C\": [1.0, 10., 25]\n",
    "})\n",
    "\n",
    "gs = GridSearchCV(LROptiPipeline(UllrichLRDetection(model=svm.SVC())), para_grid, scoring=scoring, cv=2, return_optimized=\"accuracy\").optimize(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_optimize_time</th>\n",
       "      <th>std_optimize_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>split0_test_data_labels</th>\n",
       "      <th>split1_test_data_labels</th>\n",
       "      <th>split0_train_data_labels</th>\n",
       "      <th>split1_train_data_labels</th>\n",
       "      <th>param_algo__model__C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_accuracy</th>\n",
       "      <th>split1_test_accuracy</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>std_test_accuracy</th>\n",
       "      <th>rank_test_accuracy</th>\n",
       "      <th>split0_test_single_accuracy</th>\n",
       "      <th>split1_test_single_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071965</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.112969</td>\n",
       "      <td>0.012812</td>\n",
       "      <td>[(HA, 001, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>[(HA, 002, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>[(HA, 002, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>[(HA, 001, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'algo__model__C': 1.0}</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.42857142857142855]</td>\n",
       "      <td>[0.42857142857142855]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068424</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.114587</td>\n",
       "      <td>0.006086</td>\n",
       "      <td>[(HA, 001, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>[(HA, 002, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>[(HA, 002, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>[(HA, 001, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>10.0</td>\n",
       "      <td>{'algo__model__C': 10.0}</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.14285714285714285]</td>\n",
       "      <td>[0.42857142857142855]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.069759</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.115274</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>[(HA, 001, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>[(HA, 002, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>[(HA, 002, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>[(HA, 001, TimeMeasure1, Test11, Trial1)]</td>\n",
       "      <td>25</td>\n",
       "      <td>{'algo__model__C': 25}</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.14285714285714285]</td>\n",
       "      <td>[0.5714285714285714]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_optimize_time  std_optimize_time  mean_score_time  std_score_time  \\\n",
       "0            0.071965           0.003652         0.112969        0.012812   \n",
       "1            0.068424           0.009180         0.114587        0.006086   \n",
       "2            0.069759           0.006859         0.115274        0.006507   \n",
       "\n",
       "                     split0_test_data_labels  \\\n",
       "0  [(HA, 001, TimeMeasure1, Test11, Trial1)]   \n",
       "1  [(HA, 001, TimeMeasure1, Test11, Trial1)]   \n",
       "2  [(HA, 001, TimeMeasure1, Test11, Trial1)]   \n",
       "\n",
       "                     split1_test_data_labels  \\\n",
       "0  [(HA, 002, TimeMeasure1, Test11, Trial1)]   \n",
       "1  [(HA, 002, TimeMeasure1, Test11, Trial1)]   \n",
       "2  [(HA, 002, TimeMeasure1, Test11, Trial1)]   \n",
       "\n",
       "                    split0_train_data_labels  \\\n",
       "0  [(HA, 002, TimeMeasure1, Test11, Trial1)]   \n",
       "1  [(HA, 002, TimeMeasure1, Test11, Trial1)]   \n",
       "2  [(HA, 002, TimeMeasure1, Test11, Trial1)]   \n",
       "\n",
       "                    split1_train_data_labels param_algo__model__C  \\\n",
       "0  [(HA, 001, TimeMeasure1, Test11, Trial1)]                  1.0   \n",
       "1  [(HA, 001, TimeMeasure1, Test11, Trial1)]                 10.0   \n",
       "2  [(HA, 001, TimeMeasure1, Test11, Trial1)]                   25   \n",
       "\n",
       "                     params  split0_test_accuracy  split1_test_accuracy  \\\n",
       "0   {'algo__model__C': 1.0}              0.428571              0.428571   \n",
       "1  {'algo__model__C': 10.0}              0.142857              0.428571   \n",
       "2    {'algo__model__C': 25}              0.142857              0.571429   \n",
       "\n",
       "   mean_test_accuracy  std_test_accuracy  rank_test_accuracy  \\\n",
       "0            0.428571           0.000000                   1   \n",
       "1            0.285714           0.142857                   3   \n",
       "2            0.357143           0.214286                   2   \n",
       "\n",
       "  split0_test_single_accuracy split1_test_single_accuracy  \n",
       "0       [0.42857142857142855]       [0.42857142857142855]  \n",
       "1       [0.14285714285714285]       [0.42857142857142855]  \n",
       "2       [0.14285714285714285]        [0.5714285714285714]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__model__C': 1.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__model__C': 1.0,\n",
       " 'algo__model__break_ties': False,\n",
       " 'algo__model__cache_size': 200,\n",
       " 'algo__model__class_weight': None,\n",
       " 'algo__model__coef0': 0.0,\n",
       " 'algo__model__decision_function_shape': 'ovr',\n",
       " 'algo__model__degree': 3,\n",
       " 'algo__model__gamma': 'scale',\n",
       " 'algo__model__kernel': 'rbf',\n",
       " 'algo__model__max_iter': -1,\n",
       " 'algo__model__probability': False,\n",
       " 'algo__model__random_state': None,\n",
       " 'algo__model__shrinking': True,\n",
       " 'algo__model__tol': 0.001,\n",
       " 'algo__model__verbose': False,\n",
       " 'algo__model': SVC(),\n",
       " 'algo': UllrichLRDetection(model=SVC())}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.optimized_pipeline_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UllrichLRDetection(model=SVC())"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting the optimized model.\n",
    "optimized_model = gs.optimized_pipeline_.algo\n",
    "optimized_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
